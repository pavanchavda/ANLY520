---
title: 'ANLY 520 Final Project - Sentiment Analysis of US Airline Industry Customers Tweets'
author: "Oluwatobi Akinyemi & Pavan Chavda"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
The internet has changed our lives completely. The internet is involved in almost everything we do. From shopping products online to how we keep in touch with friends and families, the internet is involved. The internet provides varierty of platform for people who want to express their thoughts and views. There are tonnes of websites that offer expert reviews on products for consumers. The social media websites such as Twitter has also given people another platform to share their feedback. Social media are interactive computer-mediated technologies that facilitate the creation and sharing of information, ideas and expressions via virtual communities [Wikipedia]. The number of social media users are huge - there are currently 7.7 billion people in the world, with at least 3.5 billion people on all social media platoforms [The rise of social media]. Twitter alone had roughly 330 million daily active users in 2019 [statista]

For companies, there is a lot of information, both relevant and irrelevant, that they can utilize to make improvements within the company. However, the challenge is to analyze the information and sort the relevant information out from all information available.

For airline industry, social media can be a great way to listen to direct consumer feedback. They are one of the largest industries in the world that serves millions of people all over the globe. The United States has the largest air travel market of any single country, with nearly 850 million people using air travel in 2017 [Passenger airlines in the U.S. - Statistics & Facts].

Sentiment analysis is a great tool for extracting useful information from social media. Sentiment analysis ia a contextual mining of text which identifies and extracts useful information from text data. It is the most common text classification tool that analyzes text data and tells whether the underlying sentiment is positive, negative or neutral. This technique can be very useful for businesses to understand the social sentiment of their brand, product or service.

## Hypothesis/Research Question
The goal of this research project is to use the twitter data to analyze the sentiments of US airlines. This research project will test the following hypothesis in this study:

* 

In addition, this research project will also explore the following research question:

* 


## Data
The dataset was taken from Crowdflower website. The data consists of all tweets by twitter users in February 2015 for 6 major airlines in the US: American, Delta, Southwest, United, US Airways, and Virgin America. There are roughly 14.5k tweets and includes 15 different variables. Each tweet has a sentiment labeled to it and there are three possible sentiments: positive, neutral and negative. For negative sentiments, the data also includes reasons such as bad flight, customer service, late flight, etc.

## Methodology
The methodology for this research project consists of the following steps:

* Data Analysis
* Data Pre-processing
* Data modeling
* Performance Analysis
* Model comparison

## Statistical Analysis
We will first load all the libraries and functions that will be used in the research project. We will also load our dataset here.

### Loading libraries
```{r libaries}
##r chunk
library("reticulate")
```
 
```{python}
##python chunk
import pandas as pd
import numpy as np
import nltk
import textblob
from bs4 import BeautifulSoup
import unicodedata
import contractions
#if you want to stem
from nltk import PorterStemmer
ps = PorterStemmer()
from model_evaluation_utils import display_model_performance_metrics
```

### Loading Data

- This dataset includes tweets that have been coded as either negative, positive or neutral. 

```{python}
##python chunk
dataset = pd.read_csv('tweets.csv')
dataset.shape
dataset.head()
print(dataset.info())
```

```{python data preprocessing}
#select desired columns
dataset = dataset[['airline','airline_sentiment','text']]
dataset.head()
```

### Data Pre-processing

Let's first clean our data using our clean_text function. The clean_text function definted below performs following steps on our text data:

* Remove HTML code
* Lowest case
* Remove contractions
* Replace all non-compatible characters with their equivalents

The clean_text function does not correct spelling as people tend to use lot of abbreviations while posting anything online and so that it doesnt consider words such as names.
```{python}
##python chunk
STOPWORDS = set(nltk.corpus.stopwords.words('english')) #stopwords
STOPWORDS.remove('no')
STOPWORDS.remove('but')
STOPWORDS.remove('not')

def clean_text(text):
    text = BeautifulSoup(text).get_text() #html
    text = text.lower() #lower case
    text = contractions.fix(text) #contractions
    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore') #symbols
    #text = ' '.join([ps.stem(word) for word in text.split()]) #stem
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # stopwords
    return text
    
dataset['text'] = dataset['text'].apply(clean_text)
dataset.head()
```

### Data Modeling

Now, let's start developing our models. We will first start the modeling using Textblob method. 

#### TextBlob
* Before running the model, we will first split our dataset into train and test data with 80/20 train/test ratio. We will calculate the polarity for all the tweets in our dataset.
* We will use the cut off score of 0 and change the polarity numbers to positive and negative categories.
* We will then convert our dataset to categorical labels to see the accuracy of our model.

```{python}
##python chunk
tweets = np.array(dataset['text'])
sentiments = np.array(dataset['airline_sentiment'])

from sklearn.model_selection import train_test_split

train_tweets, test_tweets, train_sentiments, test_sentiments = train_test_split(tweets, sentiments, test_size=0.20, random_state = 42)
train_tweets.shape
test_tweets.shape

#calculate sentiment for smaller example set
sentiment_polarity = [textblob.TextBlob(tweet).sentiment.polarity for tweet in test_tweets]

#convert to categorical labels
predicted_sentiments = ['positive' if score >= 0 else 'negative' for score in sentiment_polarity]

#display performance metrics
display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, 
                                  classes=['positive', 'negative'])
```

### AFINN

For the next model, we will use the AFINN lexicon model. It is a very popular method because of it's simplicity. Moreover, the model also considers emoticons and exclamation marks, which is great for our data as people tend to use a lot of emoticons while posting something online. In order to make sure they are preserved in our data, we will avoid cleaning the text.

```{python}
##python chunk
from afinn import Afinn

#load the model 
afn = Afinn(emoticons=True)

#predict the polarity
sentiment_polarity = [afn.score(tweet) for tweet in test_tweets]

#decide how to categorize
predicted_sentiments = ['positive' if score >= 0 else 'negative' for score in sentiment_polarity]

#display performance metrics
display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, 
                                  classes=['positive', 'negative'])
```

Now, let's train our own model using TF-IDF supervised learning approach.

### TF-IDF

- Calculate features for testing and training using the TF-IDF vectorizer.

```{python}
##python chunk
from sklearn.feature_extraction.text import TfidfVectorizer
train_tweets, test_tweets, train_sentiments, test_sentiments = train_test_split(tweets, sentiments, test_size=0.20, random_state = 42)
train_tweets.shape
test_tweets.shape

# build TFIDF features on train tweets
tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),
                     sublinear_tf=True)
tv_train_features = tv.fit_transform(train_tweets)
tv_test_features = tv.transform(test_tweets)
```

### Logistic Regression Classifier

- Create a blank logistic regression model.
- Fit the the model to the training data.
- Create the predicted value for the testing data.

```{python}
##python chunk
from sklearn.linear_model import LogisticRegression

#blank model
lr = LogisticRegression(penalty='l2', max_iter=1000, C=1)

# fit the model
lr_tfidf_model = lr.fit(tv_train_features, train_sentiments)

# grab the predictions
lr_tfidf_predictions = lr_tfidf_model.predict(tv_test_features)
```

### Accuracy and Classification Report

- Display the performance metrics of the logistic regression model on the testing data.

```{python}
##python chunk
#model performance
display_model_performance_metrics(true_labels=test_sentiments,
  predicted_labels=lr_tfidf_predictions,
  classes=['positive', 'negative'])
```


### Decision Tree Classifier

```{python}
##python chunk
from sklearn.tree import DecisionTreeClassifier

#blank model
dtree = DecisionTreeClassifier()

# fit the model
dtree_model = dtree.fit(tv_train_features, train_sentiments)

# grab the predictions
dtree_predictions = dtree_model.predict(tv_test_features)
```

#### Accuracy and Classification Report

- Display the performance metrics of the logistic regression model on the testing data.

```{python}
##python chunk
#model performance
display_model_performance_metrics(true_labels=test_sentiments,
  predicted_labels=dtree_predictions,
  classes=['positive', 'negative'])
```

### Random Forest

```{python}
##python chunk
from sklearn.ensemble import RandomForestClassifier

#blank model
rf = RandomForestClassifier(n_estimators=200)

# fit the model
rf_model = rf.fit(tv_train_features, train_sentiments)

# grab the predictions
rf_predictions =rf_model.predict(tv_test_features)
```

#### Accuracy and Classification Report

- Display the performance metrics of the logistic regression model on the testing data.

```{python}
##python chunk
#model performance
display_model_performance_metrics(true_labels=test_sentiments,
  predicted_labels=rf_predictions,
  classes=['positive', 'negative'])
```


### Topic Model

- Create a dataset of just the positive reviews. 
- Create a dictionary and document term matrix to start the topics model.

```{python}
##python chunk
#load packages
import pyLDAvis
import pyLDAvis.gensim  # don't skip this
import matplotlib.pyplot as plt
import gensim
import gensim.corpora as corpora

#create separate datasets of positive and negative tweets 
positive = dataset[dataset['airline_sentiment']=="positive"]
positive_tweets = positive['text'].apply(nltk.word_tokenize)

negative = dataset[dataset['airline_sentiment']=="negative"]
negative_tweets = negative['text'].apply(nltk.word_tokenize)

#create a dictionary of the words
dictionary_positive = corpora.Dictionary(positive_tweets)
dictionary_negative = corpora.Dictionary(negative_tweets)

#create a doc term matrix
pos_doc_term_matrix = [dictionary_positive.doc2bow(doc) for doc in positive_tweets]
neg_doc_term_matrix = [dictionary_negative.doc2bow(doc) for doc in negative_tweets]
```

#### LDA Topic Model Design

- Create the LDA Topic Model for the positive reviews with three topics.

```{python}
##python chunk
#create LDA topic model for +ve dictionary
lda_model_pos = gensim.models.ldamodel.LdaModel(
  corpus = pos_doc_term_matrix, #TDM
  id2word = dictionary_positive, #Dictionary
  num_topics = 5, 
  random_state = 100,
  update_every = 1,
  chunksize = 100,
  passes = 10,
  alpha = 'auto',
  per_word_topics = True)
```

- LDA Topic Model for the negative reviews with 10 topics.

```{python}
##python chunk
#create LDA topic model for -ve dictionary
lda_model_neg = gensim.models.ldamodel.LdaModel(
  corpus = neg_doc_term_matrix, #TDM
  id2word = dictionary_negative, #Dictionary
  num_topics = 5, 
  random_state = 100,
  update_every = 1,
  chunksize = 100,
  passes = 10,
  alpha = 'auto',
  per_word_topics = True)
```

#### Terms for the Topics

- Print out the top terms for each of the positive topics. 

```{python}
##python chunk
#Top terms in +ve dictionary
print(lda_model_pos.print_topics(num_words=10))
```

- Top terms for each of the negative topics

```{python}
##python chunk
#Top terms in +ve dictionary
print(lda_model_neg.print_topics(num_words=10))
```

#### Interactive Graphics

```{python}
##python chunk
#vis = pyLDAvis.gensim.prepare(lda_model_pos, pos_doc_term_matrix, dictionary_positive, n_jobs = 1)
#pyLDAvis.prepared_data_to_html(vis, template_type="simple")

#vis = pyLDAvis.gensim.prepare(lda_model_neg, neg_doc_term_matrix, dictionary_negative, n_jobs = 1)
#pyLDAvis.prepared_data_to_html(vis, template_type="simple")
```

## Results

- Which model best represented the polarity in the dataset? 
- Looking at the topics analysis, what are main positive components to the data?

In this section, discuss the results of our sentiment analysis. Our objective was to investigate the possibility of designing a machine learning algorithm capable of predicting sentiments from airline customers' tweets with a decent measure of precision and accurately. For the classification task, we compared the performance of five modeling methods:

- TextBlob
- AFINN lexicon method
- Logistic Regression Classifier
- Decision Tree Classifier
- Random Forest Classifier

In preparation for the last three classification methods, we Used the TF-IDF supervised learning approach to extract features, which we trained the models on before running predictions.

| Classifier | Accuracy (%) | Precision (%) | Recall (%) | f1 Score (%) |
|:-----------|:------------:|:-------------:|:----------:|:------------:|
| TextBlob   | 37.33        |      60.84    |      37.33 |      37.31   |
| AFINN      | 43.95        |      61.06    |    43.95   |    44.12     |
| Logistic Regression | 80.16 |    79.31    |    80.16   |    78.87     |
| Decision Tree | 65.2      |      69.41    |    65.2    |    66.72     |
| Random Forest | 78.55     |      77.68    |    78.55   |    77.73     |

As the above table shows, using the TF-IDF vectorizer to calculate train and test features and fitting a logistic regression model to the training data performed best for representing the polarity in the dataset. This method was able to achieve an accuracy of 80%, precision of 79.31%, and f1 score of 78.87%. This is an improvement of 1% in f1 score from the next best performing model, the random forest classifier.

## Conclusion

Social media channels have become one of the primary ways brands use to engage their customers. Platforms like microblogging site Twitter provide great utility for this purpose as they can be used as a direct lines of contact for customers to reach a company's customer service desk to seek redress of issues, information and other help. Many customers also use this medium to vend their opinions on brands and products. These opinions or reviews may be either customers' compliments or their frustrations. For this reason, the unstructured data available on Twitter is a gold mine of customer feedback, which can be mined using natural language processing methods like sentiment analysis to measure these opinions and determine ways to improve brand or product performance. 

The aim of this project was to design an algorithm capable of processing the tweets of US airline customers, and classifying them according to sentiment with precision. Of the five different algorithms tested, results showed that extracting features with the TF-IDF supervised learning approach, and fitting a model with a Logistic Regression algorithm would yield the best performing classification model by accuracy, precision, recall and f1 score.



## References
Crowdflower: https://www.crowdflower.com/data-for-everyone/

Wikipedia: https://en.wikipedia.org/wiki/Social_media

The rise of social media: https://ourworldindata.org/rise-of-social-media

Passenger airlines in the U.S. - Statistics & Facts: https://www.statista.com/topics/5575/passenger-airlines-in-the-us/

statista: https://www.statista.com/statistics/282087/number-of-monthly-active-twitter-users/